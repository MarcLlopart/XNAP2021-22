{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dkaratzas/XNAP2021-22/blob/main/Week%201%20-%20Revision/W01_03_Intro_Tensors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/dkaratzas/XNAP2021-22/blob/main/Week%201%20-%20Revision/W01_03_Intro_Tensors.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8IF4i31_7jbg"
   },
   "source": [
    "# What is PyTorch?\n",
    "\n",
    "<a href=\"https://pytorch.org/\">Pytorch</a> is a Python based scientific computing package targeted at two types of audience:\n",
    "\n",
    "-  At the low level, it is a tensor library capable to exploit the computational power of GPUs\n",
    "-  At the high level, it is a deep learning research platform that provides maximum flexibility and speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ng2mpMYgkpu"
   },
   "source": [
    "## Import the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FzX92S587jbm"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y62dQH467jbn"
   },
   "source": [
    "## Getting help in Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fastest way to get some quick help on something using Jupyter is to just ask! Type any Python object name you want followed by a question mark `?` and the code documentation will be loaded in your notebook. Try it with `torch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mType:\u001b[0m        module\n",
       "\u001b[1;31mString form:\u001b[0m <module 'torch' from 'C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\pytorch\\\\lib\\\\site-packages\\\\torch\\\\__init__.py'>\n",
       "\u001b[1;31mFile:\u001b[0m        c:\\programdata\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\__init__.py\n",
       "\u001b[1;31mDocstring:\u001b[0m  \n",
       "The torch package contains data structures for multi-dimensional\n",
       "tensors and defines mathematical operations over these tensors.\n",
       "Additionally, it provides many utilities for efficient serializing of\n",
       "Tensors and arbitrary types, and other useful utilities.\n",
       "\n",
       "It has a CUDA counterpart, that enables you to run your tensor computations\n",
       "on an NVIDIA GPU with compute capability >= 3.0.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command will list all objects of torch that with a name that finishes with \"Tensor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BIqY0-QT7jbo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.BFloat16Tensor\n",
       "torch.BoolTensor\n",
       "torch.ByteTensor\n",
       "torch.CharTensor\n",
       "torch.DoubleTensor\n",
       "torch.FloatTensor\n",
       "torch.HalfTensor\n",
       "torch.IntTensor\n",
       "torch.LongTensor\n",
       "torch.ShortTensor\n",
       "torch.Tensor"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In Colab, you can press <esc> to get out of help\n",
    "torch.*Tensor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use Colab, you also have a handy autocomplete feature at hand. For example, start writing a function name, like `torch.sqrt` if you pause after the first few characters a context menu with possible options will appear. Select the term you meant and press Tab or Enter to autocomplete. Note, this will not work in Jupyter Lab / Notebook out of the box, you would need to install an extension to enable this functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4g-D23eg7jbn"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'sq'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17356/1775242564.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msq\u001b[0m  \u001b[1;31m# complete by typing a little bit more, wait and then use <Tab> or <Enter> to autocomplete\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'sq'"
     ]
    }
   ],
   "source": [
    "torch.sq  # complete by typing a little bit more, wait and then use <Tab> or <Enter> to autocomplete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Jupyter Lab (but not in CoLab) you can access the documentation by clicking on the Python object and pressing `<Shift>` + `<Tab>`. Try it in the line below (if you are using Jupyter Lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ED3Z0RKO7jbo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Module()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Module()  # <Shift>+<Tab>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the same result as with the line below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "vrBufY4q7jbo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super(Model, self).__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool\n",
       "\u001b[1;31mInit docstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\programdata\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     Identity, Linear, Bilinear, _ConvNd, Threshold, ReLU, RReLU, Hardtanh, Sigmoid, Hardsigmoid, ...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Annotate your functions / classes!\n",
    "torch.nn.Module?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where does this documentation come from? Part of it comes from the code itself, and part of it from the annotations (special comments) that are introduced in the function / class definitions. To have a look at the actual code of a function, just use a double `??`. See for example below, and get used to annotate your functions / classes as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k6gVzBNi7jbp"
   },
   "outputs": [],
   "source": [
    "torch.nn.Module??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3odUxKDa7jbq"
   },
   "source": [
    "## Torch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the core of PyTorch there is the `Tensor` class. It is very much like numpy's arrays, but supports autograd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "dxMMJ1tO7jbq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a tensor of size 2x3x4\n",
    "t = torch.Tensor(2, 3, 4)\n",
    "type(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "P3xcTvfc7jbr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the size of the tensor\n",
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "XXAmpH-Z7jbr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "point in a 24 dimensional space\n",
      "organised in 3 sub-dimensions\n"
     ]
    }
   ],
   "source": [
    "# prints dimensional space and sub-dimensions\n",
    "print(f'point in a {t.numel()} dimensional space')\n",
    "print(f'organised in {t.dim()} sub-dimensions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "uC8XADcV7jbr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[8.9082e-39, 5.9694e-39, 8.9082e-39, 1.0194e-38],\n",
       "         [9.1837e-39, 4.6837e-39, 9.2755e-39, 1.0837e-38],\n",
       "         [8.4490e-39, 1.1112e-38, 1.0194e-38, 9.0919e-39]],\n",
       "\n",
       "        [[8.4490e-39, 9.6429e-39, 8.4490e-39, 9.6429e-39],\n",
       "         [9.2755e-39, 1.0286e-38, 9.0919e-39, 8.9082e-39],\n",
       "         [9.2755e-39, 8.4490e-39, 1.0194e-38, 9.0919e-39]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "3ARC3wOQ7jbr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[5., 5., 6., 8.],\n",
       "         [6., 5., 2., 7.],\n",
       "         [4., 7., 1., 7.]],\n",
       "\n",
       "        [[6., 1., 9., 6.],\n",
       "         [2., 9., 5., 9.],\n",
       "         [8., 6., 2., 0.]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mind the underscore!\n",
    "# Any operation that mutates a tensor in-place is post-fixed with an _.\n",
    "# For example: x.copy_(y), x.t_(), x.random_(n) will change x.\n",
    "t.random_(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "wL2ajaMg7jbs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 5., 6., 8., 6., 5., 2., 7.],\n",
       "        [4., 7., 1., 7., 6., 1., 9., 6.],\n",
       "        [2., 9., 5., 9., 8., 6., 2., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = t.view(3, 8)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "ivViPVSG7jbs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As you can see zero_ would replace r with 0's which was originally filled with integers\n",
    "r.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "-7KuYVw17jbs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "uIhTq4nIdqx7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 4, 1) (8, 1)\n",
      "torch.Size([2, 3, 4]) torch.Size([3, 8])\n"
     ]
    }
   ],
   "source": [
    "# What are strides. And how are they related to shapes?\n",
    "print(t.stride(), r.stride())\n",
    "print(t.shape, r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "Uum4hxYkffli"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 2., 4., 0.],\n",
       "         [0., 8., 9., 2.],\n",
       "         [8., 6., 3., 9.]],\n",
       "\n",
       "        [[4., 4., 1., 9.],\n",
       "         [5., 1., 0., 0.],\n",
       "         [3., 8., 8., 0.]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try that again without doing the operations in place\n",
    "t.random_(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "bJM4es_M-p2Y"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not in place\n",
    "r = t.view(3, 8)\n",
    "r = torch.zeros_like(r)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "Ivw8wI5U-12D"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 2., 4., 0.],\n",
       "         [0., 8., 9., 2.],\n",
       "         [8., 6., 3., 9.]],\n",
       "\n",
       "        [[4., 4., 1., 9.],\n",
       "         [5., 1., 0., 0.],\n",
       "         [3., 8., 8., 0.]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "dJdGqvwTdiMs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 4, 1) (8, 1)\n"
     ]
    }
   ],
   "source": [
    "# What are strides?\n",
    "print(t.stride(), r.stride())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "p6Fcui7u7jbs"
   },
   "outputs": [],
   "source": [
    "# This *is* important\n",
    "s = r.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "rm9a0zci7jbt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In-place fill of 1's\n",
    "s.fill_(1)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "Q1K3hywm7jbt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because we cloned r, even though we did an in-place operation, this doesn't affect r\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ir1URH3v7jbt"
   },
   "source": [
    "## Vectors (1D Tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "dRCvA1R17jbt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates a 1D tensor of integers 1 to 4\n",
    "v = torch.Tensor([1, 2, 3, 4])\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "wmkSLrIi7jbt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim: 1, size: 4\n"
     ]
    }
   ],
   "source": [
    "# Print number of dimensions (1D) and size of tensor\n",
    "print(f'dim: {v.dim()}, size: {v.size()[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "K03oi68R7jbu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 2., 0.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.Tensor([1, 0, 2, 0])\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "yGGpVC_b7jbu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 6., 0.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Element-wise multiplication\n",
    "v * w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "pq7-Aqs_7jbu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar product: 1*1 + 2*0 + 3*2 + 4*0\n",
    "v @ w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "x-oXbFTO7jbu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 7., 3., 9., 5.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In-place replacement of random number from 0 to 10\n",
    "x = torch.Tensor(5).random_(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "00BUa-L47jbu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first: 5.0, last: 5.0\n"
     ]
    }
   ],
   "source": [
    "print(f'first: {x[0]}, last: {x[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "ZX_Uy_T17jbu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7., 3.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract sub-Tensor [from:to)\n",
    "x[1:2 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "ZPNJt5Kt7jbv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor with integers ranging from 1 to 5, excluding 5\n",
    "v = torch.arange(1, 4 + 1)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "7_nwZPg-7jbv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  4,  9, 16]) tensor([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Square all elements in the tensor\n",
    "print(v.pow(2), v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "De7wobZv7jbv"
   },
   "source": [
    "## Matrices (2D Tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "JuiyP0MK7jbv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 5., 3., 7.],\n",
       "        [4., 2., 1., 9.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 2x4 tensor\n",
    "m = torch.Tensor([[2, 5, 3, 7],\n",
    "                  [4, 2, 1, 9]])\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "xI36U8sv7jbv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "7f91z4dw7jbw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 -- 4 -- torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "print(m.size(0), m.size(1), m.size(), sep=' -- ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "4vuLnT2z7jbw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing row 0, column 2 (0-indexed)\n",
    "m[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "YLIC7pG97jbw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing row 0, column 2 (0-indexed)\n",
    "m[0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "tsutF_zc7jbw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 2.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing column 1, all rows (returns size 2)\n",
    "m[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "cLg24cHx7jbw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.],\n",
       "        [2.]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing column 1, all rows (returns size 2x1)\n",
    "m[:, [1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "F8nu79EU7jbx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.,  5.,  3.,  7.]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexes row 0, all columns (returns 1x4)\n",
    "m[[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "oYVpTC7l7jbx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensor of numbers from 1 to 4 (excluding 5)\n",
    "v = torch.arange(1., 5)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "0UQd3S3w7jbx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.,  5.,  3.,  7.],\n",
       "        [ 4.,  2.,  1.,  9.]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "c10o4XUQ7jbx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([46., 47.])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar product\n",
    "m @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "fEkCtsZG7jbx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(46.)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated by 1*2 + 2*5 + 3*3 + 4*7\n",
    "m[0, :] @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "HzxKEjus7jby"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([47.])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated by \n",
    "m[[1], :] @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "mP7c5qI17jby"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.4030, 5.6396, 3.0400, 7.7285],\n",
       "        [4.9804, 2.4101, 1.1023, 9.0844]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a random tensor of size 2x4 to m\n",
    "m + torch.rand(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "nli9YIb17jby"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5959, 4.5076, 2.4442, 6.4373],\n",
       "        [3.1234, 1.5907, 0.3573, 8.7657]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtract a random tensor of size 2x4 to m\n",
    "m - torch.rand(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "v0QPbbr87jby"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9835, 3.4594, 1.2920, 5.8008],\n",
       "        [2.7080, 1.1715, 0.3524, 5.0658]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply a random tensor of size 2x4 to m\n",
    "m * torch.rand(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "wRxwhq3p7jby"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  3.7331,  24.0532,   5.9154,  11.4908],\n",
       "        [ 19.6228,   3.3938,   2.9937, 107.1191]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divide m by a random tensor of size 2x4\n",
    "m / torch.rand(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "MFjUamkg7jby"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "88uWT_-N7jbz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 4.],\n",
       "        [5., 2.],\n",
       "        [3., 1.],\n",
       "        [7., 9.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transpose tensor m, which is essentially 2x4 to 4x2\n",
    "m.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "hfx8uRtl7jbz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 4.],\n",
       "        [5., 2.],\n",
       "        [3., 1.],\n",
       "        [7., 9.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same as\n",
    "m.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3p2bHHeHJewn"
   },
   "source": [
    "## Broadcasting\n",
    "\n",
    "Two tensors are “broadcastable” if the following rules hold:\n",
    "\n",
    "*   Each tensor has at least one dimension.\n",
    "*   When iterating over the dimension sizes, starting at the trailing dimension, the dimension sizes must either be equal, one of them is 1, or one of them does not exist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "pPyg44mxJeHP"
   },
   "outputs": [],
   "source": [
    "x=torch.empty(5,7,3)\n",
    "y=torch.empty(5,7,3)\n",
    "# x and y are broadcastable since all dimensions are equal\n",
    "\n",
    "x=torch.empty((0,))\n",
    "y=torch.empty(2,2)\n",
    "# x and y are not broadcastable, because x does not have at least 1 dimension\n",
    "\n",
    "x=torch.empty(5,3,4,1)\n",
    "y=torch.empty(  3,1,1)\n",
    "# x and y are broadcastable.\n",
    "# 1st trailing dimension: both have size 1\n",
    "# 2nd trailing dimension: y has size 1\n",
    "# 3rd trailing dimension: x size == y size\n",
    "# 4th trailing dimension: y dimension doesn't exist\n",
    "\n",
    "# but:\n",
    "x=torch.empty(5,2,4,1)\n",
    "y=torch.empty(  3,1,1)\n",
    "# x and y are not broadcastable, because in the 3rd trailing dimension 2 != 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "MpudbDP9MI4U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 4, 1])\n",
      "torch.Size([3, 1, 7])\n"
     ]
    }
   ],
   "source": [
    "# How is the output dimension calculated?\n",
    "x=torch.empty(5,1,4,1)\n",
    "y=torch.empty(3,1,1)\n",
    "print((x+y).size())\n",
    "\n",
    "x=torch.empty(1)\n",
    "y=torch.empty(3,1,7)\n",
    "print((x+y).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpCZhT8U7jbz"
   },
   "source": [
    "## Constructors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "ZYn7XeYu7jbz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4., 5., 6., 7., 8.])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensor from 3 to 8\n",
    "torch.arange(3., 8 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "XH8X7Dts7jbz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.7000,  2.7000, -0.3000])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensor from 5.7 to -2.1 with step -3\n",
    "torch.arange(5.7, -2.1, -3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "3B14Dyrn7jbz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.0000, 3.2632, 3.5263, 3.7895, 4.0526, 4.3158, 4.5789, 4.8421, 5.1053,\n",
       "         5.3684, 5.6316, 5.8947, 6.1579, 6.4211, 6.6842, 6.9474, 7.2105, 7.4737,\n",
       "         7.7368, 8.0000]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns a 1D tensor of equally spaced elements between start=3, end=8 and number of elements=20\n",
    "torch.linspace(3, 8, 20).view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "tb4KEmjU7jb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor filled with 0's\n",
    "torch.zeros(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "TrOxrng27jb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor filled with 1's\n",
    "torch.ones(3, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "xt6VUo1A7jb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor with the diagonal filled with 1\n",
    "torch.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "oDCnuhOf7jb0"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "81dgFtq67jb0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Numpy bridge!\n",
    "plt.hist(torch.randn(1000).numpy(), 100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "pBhx09297jb1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(torch.randn(10**6).numpy(), 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SyeN3wTV7jb1"
   },
   "source": [
    "## Casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "MxMGbcNP7jb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.BFloat16Tensor\n",
       "torch.BoolTensor\n",
       "torch.ByteTensor\n",
       "torch.CharTensor\n",
       "torch.DoubleTensor\n",
       "torch.FloatTensor\n",
       "torch.HalfTensor\n",
       "torch.IntTensor\n",
       "torch.LongTensor\n",
       "torch.ShortTensor\n",
       "torch.Tensor"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Helper to get what kind of tensor types\n",
    "torch.*Tensor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "-6pXTH4b7jb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 5., 3., 7.],\n",
       "        [4., 2., 1., 9.]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.Tensor([[2, 5, 3, 7],\n",
    "                  [4, 2, 1, 9]])\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "3TAG0hTN7jb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 5., 3., 7.],\n",
       "        [4., 2., 1., 9.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is basically a 64 bit float tensor\n",
    "m_double = m.double()\n",
    "m_double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "hFe9nMZi7jb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 3, 7],\n",
       "        [4, 2, 1, 9]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This creates a tensor of type int8\n",
    "m_byte = m.byte()\n",
    "m_byte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "FSVzhX_I7jb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 5., 3., 7.],\n",
       "       [4., 2., 1., 9.]], dtype=float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converts tensor to numpy array\n",
    "m_np = m.numpy()\n",
    "m_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "BHfSv9BB7jb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.,  5.,  3.,  7.],\n",
       "       [ 4.,  2.,  1.,  9.]], dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In-place fill of column 0 and row 0 with value -1\n",
    "m_np[0, 0] = -1\n",
    "m_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "ICAeMZLU7jb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.,  5.,  3.,  7.],\n",
       "        [ 4.,  2.,  1.,  9.]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "CStd3ORV7jb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4] tensor([0, 1, 2, 3, 4], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor of integers ranging from 0 to 4\n",
    "import numpy as np\n",
    "n_np = np.arange(5)\n",
    "n = torch.from_numpy(n_np)\n",
    "print(n_np, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "3gGi0E-h7jb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 4, 6, 8])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In-place multiplication of all elements by 2 for tensor n\n",
    "n.mul_(2)\n",
    "n_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9yGGuawb7jb3"
   },
   "source": [
    "## Using the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "V3cSABmzDda2"
   },
   "outputs": [],
   "source": [
    "# If this cell fails you need to change the runtime of your colab notebook to GPU\n",
    "# Go to Runtime -> Change Runtime Type and select GPU\n",
    "assert torch.cuda.is_available(), \"GPU is not enabled\"\n",
    "\n",
    "# use the first gpu available if possible\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "2rQvVYDMFIAW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor's device: cpu\n",
      "tensor's device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Tensors can be moved between gpu and cpu memory\n",
    "\n",
    "tensor = torch.randn(5, 5) # create a 5x5 matrix filled with random numbers\n",
    "print(f\"tensor's device: {tensor.device}\") # by default tensors are stored in cpu memory (RAM)\n",
    "\n",
    "# Move your tensor to GPU device 0 if there is one (first GPU in the system)\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to(device) # tensor.cuda() is an alternative although not recommended\n",
    "print(f\"tensor's device: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "ccZpZ5xzZ8Sy"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17356/3291049658.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# This throws an exception, since you can't operate on tensors stored in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# different devices, and the error message is pretty clear about that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "# A common mistake \n",
    "a = torch.randn(5, 2, device=device)\n",
    "b = torch.randn(1, 2)\n",
    "\n",
    "# This throws an exception, since you can't operate on tensors stored in\n",
    "# different devices, and the error message is pretty clear about that\n",
    "c = a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x59Bo0QnEUOU"
   },
   "source": [
    "# Gradient Computation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "H25IsxuRKlry"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of a with respecto to L: tensor([36., 81.])\n"
     ]
    }
   ],
   "source": [
    "# Tensors also track the operations applied on them in order to differentiate them\n",
    "\n",
    "# setting requires_grad to true tells the autograd engine that we want to compute\n",
    "# gradients for this tensor\n",
    "a = torch.tensor([2., 3.], requires_grad=True)\n",
    "\n",
    "L = 3*a**3\n",
    "L.sum().backward()\n",
    "print(f\"Gradient of a with respecto to L: {a.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnviODjmRdKC"
   },
   "source": [
    "Lets check if the computed gradients are correct:\n",
    "\n",
    "$\\frac{\\partial{L}}{\\partial{a}} = [9 * a_1^2, 9 * a_2^2]$\n",
    "\n",
    "$\\frac{\\partial{L}}{\\partial{a}} = [9 * 2^2, 9 * 3^2]$\n",
    "\n",
    "$\\frac{\\partial{L}}{\\partial{a}} = [36, 81]$\n",
    "\n",
    "As we can see the gradient vector matches the one computed by the autograd engine (no surprise there)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "61qpDwtvU_E8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does a require gradients? : False\n",
      "Does b require gradients?: True\n"
     ]
    }
   ],
   "source": [
    "# Notice that the output tensor of an operation will require gradients even \n",
    "# if only a single input tensor has requires_grad=True.\n",
    "\n",
    "x = torch.rand(5, 5)\n",
    "y = torch.rand(5, 5)\n",
    "z = torch.rand((5, 5), requires_grad=True)\n",
    "\n",
    "a = x + y\n",
    "print(f\"Does a require gradients? : {a.requires_grad}\")\n",
    "b = x + z\n",
    "print(f\"Does b require gradients?: {b.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-_70bB17jb4"
   },
   "source": [
    "## Much more\n",
    "\n",
    "There's definitely much more, but this was the basics about `Tensor`s fun.\n",
    "\n",
    "*Torch* full API can be found [here](https://pytorch.org/docs/stable/index.html).\n",
    "You'll find 100+ `Tensor` operations, including transposing, indexing, slicing, mathematical operations, linear algebra, random numbers, etc are described."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Xl6U-RoEtY3"
   },
   "source": [
    "# Homework\n",
    "\n",
    "<font color=\"blue\">**Exercise 1:** The code below simulates a tiny neural network, however it throws an exception. As you build neural networks in PyTorch you will see this exception often. Look at the error message, explain whats happening and make the necessary changes to the code to get an output from this tiny network</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5aGsG2MMGebg"
   },
   "outputs": [],
   "source": [
    "### Generate some data\n",
    "torch.manual_seed(7) # Set the random seed so things are predictable\n",
    "\n",
    "# Features are 5 random normal variables\n",
    "features = torch.randn((1, 5))\n",
    "# True weights for our data, random normal variables again\n",
    "weights = torch.randn_like(features)\n",
    "# and a true bias term\n",
    "bias = torch.randn((1, 1))\n",
    "fts = torch.mm(features, weights)\n",
    "print(fts + bias)\n",
    "print(fts.shape, bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Exercise 2:** Once you manage to sucessfully run the code below notice how the shape of the tensors ```fts``` and ```bias``` are drastically different, yet they can be added together. Which internal PyTorch mechanism makes this addition happen?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8N-hhzmQZaA"
   },
   "source": [
    "# More Homework\n",
    "\n",
    "<font color=\"blue\">**Exercise 3:** Answer the following questions about the cell below</font>\n",
    "\n",
    "1. Does the value of ```t``` change? Why?\n",
    "2. Does the shape of ```t``` change? Why?\n",
    "3. Explain, in your own words. What is the stride of a tensor, why is it convenient to have them?\n",
    "4.  Pick a mathematical operation like cosine or square root (not those though 🙂). Can you find the correspoding function in the [torch library](https://https://pytorch.org/docs/stable/torch.html#pointwise-ops). \n",
    "5. Apply the function element-wise to ```a```.\n",
    "6. Is there a version of the function that operates in place? Does it return an error? Why? How can it be fixed?\n",
    "7. Run the same function on the GPU. Do you notice any difference in runtime? If not, why do you think that is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "__SC70eiXYn1"
   },
   "outputs": [],
   "source": [
    "t = torch.tensor(list(range(9)))\n",
    "\n",
    "a = t.view(3, 3)\n",
    "a.mul_(2)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "tensors.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
